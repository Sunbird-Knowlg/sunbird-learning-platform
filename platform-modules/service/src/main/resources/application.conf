LearningActorSystem {
  akka {
    actor {
    	default-dispatcher {
      		type = "Dispatcher"
    		executor = "fork-join-executor"
    		fork-join-executor {
        		parallelism-min = 1
        		parallelism-factor = 2.0
        		parallelism-max = 4
    		}
      		# Throughput for default Dispatcher, set to 1 for as fair as possible
      		throughput = 1
    	}
    }
  }
}

# Learning-Service Configuration
content.metadata.visibility.parent=["textbookunit", "courseunit", "lessonplanunit"]

# Cassandra Configuration
content.keyspace.name=content_store
cassandra.lp.connection="127.0.0.1:9042,127.0.0.2:9042,127.0.0.3:9042"
cassandra.lpa.connection="127.0.0.1:9042,127.0.0.2:9042,127.0.0.3:9042"

# Redis Configuration
redis.host=localhost
redis.port=6379
redis.maxConnections=128

#Condition to enable publish locally
content.publish_task.enabled=true

#directory location where store unzip file
dist.directory=/data/tmp/dist/
output.zipfile=/data/tmp/story.zip
source.folder=/data/tmp/temp2/
save.directory=/data/tmp/temp/

# Content 2 vec analytics URL
CONTENT_TO_VEC_URL="http://172.31.27.233:9000/content-to-vec"

# FOR CONTENT WORKFLOW PIPELINE (CWP)

#--Content Workflow Pipeline Mode
OPERATION_MODE=TEST

#--Maximum Content Package File Size Limit in Bytes (50 MB)
MAX_CONTENT_PACKAGE_FILE_SIZE_LIMIT=52428800

#--Maximum Asset File Size Limit in Bytes (20 MB)
MAX_ASSET_FILE_SIZE_LIMIT=20971520

#--No of Retry While File Download Fails
RETRY_ASSET_DOWNLOAD_COUNT=1

#Google-vision-API
google.vision.tagging.enabled = false

#Orchestrator env properties
env="https://dev.ekstep.in/api/learning"

#Current environment
cloud_storage.env=dev


#Folder configuration
cloud_storage.content.folder=content
cloud_storage.itemset.folder = "itemset"
cloud_storage.asset.folder=assets
cloud_storage.artefact.folder=artifact
cloud_storage.bundle.folder=bundle
cloud_storage.media.folder=media
cloud_storage.ecar.folder=ecar_files

# Media download configuration
content.media.base.url="https://dev.open-sunbird.org"
plugin.media.base.url="https://dev.open-sunbird.org"

# Graph Configuration
graph.dir=/data/graphDB
akka.request_timeout=30
environment.id=10000000
graph.ids=["domain"]
graph.passport.key.base=31b6fd1c4d64e745c867e61a45edc34a
route.domain="bolt://localhost:7687"
route.bolt.write.domain="bolt://localhost:7687"
route.bolt.read.domain="bolt://localhost:7687"
route.bolt.comment.domain="bolt://localhost:7687"
route.all="bolt://localhost:7687"
route.bolt.write.all="bolt://localhost:7687"
route.bolt.read.all="bolt://localhost:7687"
route.bolt.comment.all="bolt://localhost:7687"

shard.id=1
platform.auth.check.enabled=false
platform.cache.ttl=3600000

# Elasticsearch properties
search.es_conn_info="localhost:9200"
search.fields.query=["name^100","title^100","lemma^100","code^100","tags^100","domain","subject","description^10","keywords^25","ageGroup^10","filter^10","theme^10","genre^10","objects^25","contentType^100","language^200","teachingMode^25","skills^10","learningObjective^10","curriculum^100","gradeLevel^100","developer^100","attributions^10","owner^50","text","words","releaseNotes"]
search.fields.date=["lastUpdatedOn","createdOn","versionDate","lastSubmittedOn","lastPublishedOn"]
search.batch.size=500
search.connection.timeout=30
platform-api-url="http://localhost:8080/language-service"
MAX_ITERATION_COUNT_FOR_SAMZA_JOB=2


# DIAL Code Configuration
dialcode.keyspace.name="dialcode_store"
dialcode.keyspace.table="dial_code"
dialcode.max_count=1000

# System Configuration
system.config.keyspace.name="dialcode_store"
system.config.table="system_config"

#Publisher Configuration
publisher.keyspace.name="dialcode_store"
publisher.keyspace.table="publisher"

#DIAL Code Generator Configuration
dialcode.strip.chars="0"
dialcode.length=6.0
dialcode.large.prime_number=1679979167

#DIAL Code ElasticSearch Configuration
dialcode.index=true
dialcode.object_type="DialCode"

framework.max_term_creation_limit=200

# Enable Suggested Framework in Get Channel API.
channel.fetch.suggested_frameworks=true

# Kafka configuration details
kafka.topics.instruction="local.learning.job.request"
kafka.urls="localhost:9092"

#Youtube Standard Licence Validation
learning.content.youtube.validate.license=true
learning.content.youtube.application.name=fetch-youtube-license
youtube.license.regex.pattern=["\\?vi?=([^&]*)", "watch\\?.*v=([^&]*)", "(?:embed|vi?)/([^/?]*)","^([A-Za-z0-9\\-\\_]*)"]

#Top N Config for Search Telemetry
telemetry_env=dev
telemetry.search.topn=5

installation.id=ekstep

learning.content.copy.invalid_status_list=["Flagged","FlaggedDraft","FraggedReview","Retired", "Processing"]
learning.content.copy.props_to_remove=["downloadUrl", "artifactUrl", "variants",
	"createdOn", "collections", "children", "lastUpdatedOn", "SYS_INTERNAL_LAST_UPDATED_ON",
	"versionKey", "s3Key", "status", "pkgVersion", "toc_url", "mimeTypesCount",
	"contentTypesCount", "leafNodesCount", "childNodes", "prevState", "lastPublishedOn",
	"flagReasons", "compatibilityLevel", "size", "publishChecklist", "publishComment",
	"LastPublishedBy", "rejectReasons", "rejectComment", "gradeLevel", "subject",
	"medium", "board", "topic", "purpose", "subtopic", "contentCredits",
	"owner", "collaborators", "creators", "contributors", "badgeAssertions", "dialcodes",
	"concepts", "keywords", "reservedDialcodes", "dialcodeRequired", "leafNodes"]

# Metadata to be added to copied content from origin
learning.content.copy.origin_data=["name", "author", "license", "organisation"]

learning.content.type.not.copied.list=["Asset"]

channel.default="in.ekstep"

# DialCode Link API Config
learning.content.link_dialcode_validation=true
dialcode.api.search.url="http://localhost:8080/learning-service/v3/dialcode/search"
dialcode.api.authorization=auth_key

# Language-Code Configuration
language.graph_ids=["as","bn","en","gu","hi","hoc","jun","ka","mai","mr","unx","or","san","sat","ta","te","urd", "pj"]

# Kafka send event to topic enable
kafka.topic.send.enable=false

learning.valid_license=["creativeCommon"]
learning.service_provider=["youtube"]

stream.mime.type=video/mp4
compositesearch.index.name="compositesearch"

hierarchy.keyspace.name=hierarchy_store
content.hierarchy.table=content_hierarchy
framework.hierarchy.table=framework_hierarchy

# Kafka topic for definition update event.
kafka.topic.system.command="dev.system.command"

learning.reserve_dialcode.mimeType=["application/vnd.ekstep.content-collection"]
# restrict.metadata.objectTypes=["Content", "ContentImage", "AssessmentItem", "Channel", "Framework", "Category", "CategoryInstance", "Term"]

#restrict.metadata.objectTypes="Content,ContentImage"

publish.collection.fullecar.disable=true

# Consistency Level for Multi Node Cassandra cluster
cassandra.lp.consistency.level=QUORUM

content.nested.fields="badgeAssertions,targets,badgeAssociations"

content.cache.ttl=86400
content.cache.read=true
content.cache.hierarchy=true
content.discard.status=["Draft","FlagDraft"]

framework.categories_cached=["subject", "medium", "gradeLevel", "board"]
framework.cache.ttl=86400
framework.cache.read=true


# Max size(width/height) of thumbnail in pixels
max.thumbnail.size.pixels=150

content.tagging.backward_enable=true
content.tagging.property="subject,medium"

# This is added to handle large artifacts sizes differently
content.artifact.size.for_online=209715200


cloudstorage {
  metadata.replace_absolute_path=true
  relative_path_prefix={{ cloudstorage_relative_path_prefix_content }}
  metadata.list={{ cloudstorage_metadata_list }}
  read_base_path="{{ cloudstorage_base_path }}"
  write_base_path={{ valid_cloudstorage_base_urls }}
}
cloud_storage_container="{{ cloud_storage_content_bucketname }}"