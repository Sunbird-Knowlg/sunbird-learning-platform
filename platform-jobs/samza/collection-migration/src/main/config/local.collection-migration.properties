# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=local.collection-migration

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz
yarn.container.memory.mb=2048

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Task
task.class=org.ekstep.jobs.samza.task.CollectionMigrationTask
task.inputs=kafka.local.learning.job.request
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.commit.ms=60000
task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y
task.window.ms=300000
#task.opts=-Dfile.encoding=UTF8
task.broadcast.inputs=kafka.local.system.command#0

# Serializers
serializers.registry.json.class=org.ekstep.jobs.samza.serializers.EkstepJsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.bootstrap.servers=localhost:9092

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

# Job specific config properties
graph.dir="/data/graphDB"
redis.host=localhost
redis.port=6379
redis.maxConnections=128
akka.request_timeout=30
environment.id=10000000
graph.ids=["domain","language","en","hi","ka","te","ta"]
graph.passport.key.base=31b6fd1c4d64e745c867e61a45edc34a
route.domain=bolt://localhost:7687
route.bolt.write.domain=bolt://localhost:7687
route.bolt.read.domain=bolt://localhost:7687
route.bolt.comment.domain=bolt://localhost:7687
route.all=bolt://localhost:7687
route.bolt.write.all=bolt://localhost:7687
route.bolt.read.all=bolt://localhost:7687
route.bolt.comment.all=bolt://localhost:7687
shard.id=1

content.keyspace.name=content_store
content.keyspace.table=content_data
hierarchy.keyspace.name=hierarchy_store
content.hierarchy.table=content_hierarchy
CONTENT_TO_VEC_URL="http://172.31.27.233:9000/content-to-vec"
platform-api-url=http://localhost:8080/learning-service
ekstepPlatformApiUserId=ilimi
platform.auth.check.enabled=false
platform.cache.ttl=3600000
backend_telemetry_topic=local.telemetry.backend
failed_event_topic=local.learning.job.request

# Metrics
output.metrics.job.name=collection-migration
output.metrics.topic.name=local.pipeline_metrics

#Failed Topic Config
output.failed.events.topic.name=local.learning.events.failed

cassandra.lp.connection=localhost:9042

# Consistency Level for Multi Node Cassandra cluster
cassandra.lp.consistency.level=QUORUM

#directory location where drive media files are
tmp.download.directory = /data/tmp/temp/
tmp.upload.directory = /data/tmp/temp/


#Current environment
cloud_storage.env=dev

#Folder configuration
cloud_storage.content.folder=content
cloud_storage.asset.folder=assets
cloud_storage.artefact.folder=artifact
cloud_storage.bundle.folder=bundle
cloud_storage.media.folder=media
cloud_storage.ecar.folder=ecar_files
cloud_storage.upload.url.ttl=600

channel.default=in.ekstep

kafka.topics.instruction=local.learning.job.request
kafka.urls=localhost:9092

search.config.path=/home/learning/platform/search

# Cache-Manager Configuration
cache.type=redis

search.es_conn_info=localhost:9200
search.fields.query=["name^100","title^100","lemma^100","code^100","tags^100","question^100","domain","subject","description^10","keywords^25","ageGroup^10","filter^10","theme^10","genre^10","objects^25","contentType^100","language^200","teachingMode^25","skills^10","learningObjective^10","curriculum^100","gradeLevel^100","developer^100","attributions^10","owner^50","text","words","releaseNotes","body"]
search.fields.date=["lastUpdatedOn","createdOn","versionDate","lastSubmittedOn","lastPublishedOn"]
search.fields.mode_collection=["identifier","name","objectType","contentType","mimeType","size","childNodes"]
search.batch.size=500
search.connection.timeout=30
