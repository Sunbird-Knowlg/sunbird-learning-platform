# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=dev.audit-history-indexer

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.dev.lp.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Task
task.class=org.ekstep.jobs.samza.task.AuditHistoryIndexerTask
task.inputs=kafka.dev.learning.graph.events
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.commit.ms=60000
task.window.ms=300000
task.opts=-Dfile.encoding=UTF8

# Serializers
serializers.registry.json.class=org.ekstep.jobs.samza.serializers.EkstepJsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.bootstrap.servers=localhost:9092

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

# Job specific config properties
search.es_conn_info=localhost:9200


# Metrics
output.metrics.job.name=audit-history-indexer
output.metrics.topic.name=dev.pipeline_metrics