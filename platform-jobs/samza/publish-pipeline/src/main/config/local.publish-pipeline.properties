# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=dev.publish.pipeline

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.dev.lp.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Task
task.class=org.ekstep.jobs.samza.task.PublishPipelineTask
#task.inputs=kafka.telemetry.raw
task.inputs=kafka.dev.learning.job.request
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.commit.ms=60000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y
task.window.ms=300000
task.opts=-Dfile.encoding=UTF8
task.broadcast.inputs=kafka.dev.system.command#0

# Serializers
serializers.registry.json.class=org.ekstep.jobs.samza.serializers.EkstepJsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.bootstrap.servers=localhost:9092

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

# Job specific config properties
graph.dir="/data/graphDB"
redis.host=localhost
redis.port=6379
redis.maxConnections=128
akka.request_timeout=30
environment.id=10000000
graph.ids=domain
graph.passport.key.base=31b6fd1c4d64e745c867e61a45edc34a
route.domain=bolt://localhost:7687
route.bolt.write.domain=bolt://localhost:7687
route.bolt.read.domain=bolt://localhost:7687
route.bolt.comment.domain=bolt://localhost:7687
route.all=bolt://localhost:7687
route.bolt.write.all=bolt://localhost:7687
route.bolt.read.all=bolt://localhost:7687
route.bolt.comment.all=bolt://localhost:7687
shard.id=1
platform.auth.check.enabled=false
platform.cache.ttl=3600000
backend_telemetry_topic=local.telemetry.backend
failed_event_topic=local.learning.job.request

#Current environment
cloud_storage.env=dev

#Folder configuration
cloud_storage.content.folder=content
cloud_storage.asset.folder=assets
cloud_storage.artefact.folder=artifact
cloud_storage.bundle.folder=bundle
cloud_storage.media.folder=media
cloud_storage.ecar.folder=ecar_files
cloud_storage.upload.url.ttl=600


# Media download configuration
content.media.base.url=https://dev.ekstep.in
plugin.media.base.url=https://dev.ekstep.in

#directory location where store unzip file
dist.directory = /data/tmp/dist/
output.zipfile = /data/tmp/story.zip
source.folder  = /data/tmp/temp2/
save.directory = /data/tmp/temp/

MAX_CONTENT_PACKAGE_FILE_SIZE_LIMIT = 52428800
MAX_ASSET_FILE_SIZE_LIMIT = 20971520
RETRY_ASSET_DOWNLOAD_COUNT = 1

platform-api-url=http://localhost:8080/learning-service

lp.tempfile.location=__lp_tmpfile_location__
publish.collection.fullecar.disable=true
max.iteration.count.samza.job=2
publish.content.limit=200

#Remote Debug Configuration 
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Metrics
output.metrics.job.name=publish-pipeline
output.metrics.topic.name=__env__.pipeline_metrics

#Failed Topic Config
output.failed.events.topic.name=local.learning.events.failed

telemetry_env=LOCAL
# Configuration for default channel ID
channel.default=in.ekstep

#Streamable media type list
stream.mime.type=video/mp4,video/webm
stream.keyspace.name=platform_db
stream.keyspace.table=job_request

cassandra.lp.connection="localhost:9042"
cassandra.lpa.connection="localhost:9042"

restrict.metadata.objectTypes=Content,ContentImage

content.nested.fields=badgeAssertions,targets,badgeAssociations