---
- name: Create Directory for Jobs
  file: path={{item}} owner=hduser group=hadoop recurse=yes state=directory
  with_items:
    - "{{samza_jobs_dir}}"
    - "{{samza_jobs_dir}}/extract"

- name: Copy script to get all running jobs
  copy: src=get_all_running_app_name.sh dest=/usr/local/hadoop/bin owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Copy script to get all job names
  copy: src=get_all_job_name.sh dest="{{samza_jobs_dir}}/extract" owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Copy script to get updated job names from extracted tar
  copy: src=update_new_job_name.sh dest="{{samza_jobs_dir}}/extract" owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Copy script to start jobs based on the status
  copy: src=start_jobs.sh dest="{{samza_jobs_dir}}/extract" owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Copy script to remove old job tar
  copy: src=remove_old_tar.sh dest="{{samza_jobs_dir}}/extract" owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Copy script to kill jobs based on the status
  copy: src=kill_jobs.sh dest=/usr/local/hadoop/bin owner=hduser group=hadoop mode="u=rwx,g=rx,o=r"

- name: Remove file of job status
  file: path="{{job_status_file}}" state=absent

- name: Get job names from folder
  command: bash -lc "./get_all_job_name.sh {{job_status_file}}"
  args:
    chdir: "{{samza_jobs_dir}}/extract"

- name: Ensure yarn resource manager is running
  command: bash -lc "(ps aux | grep yarn-hduser-resourcemanager | grep -v grep) || /usr/local/hadoop/sbin/yarn-daemon.sh --config /usr/local/hadoop-{{hadoop_version}}/conf/ start resourcemanager"
  become: yes
  become_user: hduser

- name: Update status of running job in file
  command: bash -lc "./get_all_running_app_name.sh {{job_status_file}}"
  args:
    chdir: /usr/local/hadoop/bin

- name: copy new jobs tar ball
  copy: src={{ item }} dest={{samza_jobs_dir}}/ force=no owner=hduser group=hadoop
  with_fileglob:
    - ./jobs/*
  register: new_jobs

- name: Create Directory to extract new jobs
  file: path={{samza_jobs_dir}}/extract/{{item.item | basename }} owner=hduser group=hadoop recurse=yes state=directory
  register: extract_dir
  when: "{{item|changed}}"
  with_items: "{{ (new_jobs|default({})).results|default([]) }}"

- name: extract new jobs
  command: tar -xvf "{{samza_jobs_dir}}/{{item.item | basename}}" -C "{{samza_jobs_dir}}/extract/{{item.item | basename }}"
  when: "{{item|changed}}"
  with_items: "{{ (new_jobs|default({})).results|default([]) }}"

- name: Create Directory to extract new jobs
  file: path={{samza_jobs_dir}}/extract/ owner=hduser group=hadoop recurse=yes

- name: Get all new job configs
  shell: "ls -d -1 {{item.path}}/config/*.properties"
  register: config_files
  when: "{{item|changed}}"
  with_items: "{{ (extract_dir|default({})).results|default([]) }}"

- name: update environment specific details in new job configs
  replace: dest="{{item[1].stdout}}" regexp="{{item[0].key}}" replace="{{item[0].value}}"
  when: "{{item[1]|changed}}"
  with_nested:
    - [{key: "__yarn_host__", value: "{{__yarn_host__}}"}, {key: "__yarn_port__", value: "{{__yarn_port__}}"}, {key: "__env__", value: "{{env}}" }, {key: "__env_name__", value: "{{env_name}}" }, {key: "__zookeepers__", value: "{{zookeepers}}"}, {key: "__kafka_brokers__", value: "{{kafka_brokers}}"}, {key: "__delayInMilliSeconds__", value: "{{delayInMilliSeconds}}" }, {key: "__retryTimeInMilliSeconds__", value: "{{retryTimeInMilliSeconds}}" }, {key: "__bypass_reverse_search__", value: "{{bypass_reverse_search}}" }, {key: "__retryBackoffBaseInSeconds__", value: "{{retry_backoff_base_in_seconds}}" }, {key: "__retryLimit__", value: "{{retry_limit}}" }, {key: "__retryLimitEnable__", value: "{{retry_limit_enable}}" },  {key: "__google_api_key__", value: "{{google_api_key}}" }, {key: "__searchServiceEndpoint__", value: "{{search_service_endpoint}}" }, {key: "__objectDenormalizationAdditionalConfig__", value: "{{object_denormalization_additional_config}}" },{key: "__audit_es_host__", value: "{{audit_es_host}}"}, {key: "__search_es_host__", value: "{{search_es_host}}"}, {key: "__redis_host__", value: "{{redis_host}}"}, {key: "__redis_port__", value: "{{redis_port}}"}, {key: "__environment_id__", value: "{{environment_id}}"}, {key: "__graph_passport_key__", value: "{{graph_passport_key}}"}, {key: "__lp_bolt_url__", value: "{{lp_bolt_url}}"}, {key: "__lp_bolt_read_url__", value: "{{lp_bolt_read_url}}"}, {key: "__lp_bolt_write_url__", value: "{{lp_bolt_write_url}}"}, {key: "__other_bolt_url__", value: "{{other_bolt_url}}"}, {key: "__other_bolt_read_url__", value: "{{other_bolt_read_url}}"}, {key: "__other_bolt_write_url__", value: "{{other_bolt_write_url}}"}, {key: "__mw_shard_id__", value: "{{mw_shard_id}}"}, {key: "__lp_url__", value: "{{lp_url}}"}, {key: "__cloud_storage_config_environment__", value: "{{cloud_storage_config_environment}}"}, {key: "__google_vision_tagging__", value: "{{google_vision_tagging}}"}, {key: "__lp_tmpfile_location__", value: "{{lp_tmpfile_location}}"}, {key: "__esRouterAdditionalConfig__", value: "{{es_router_additional_config}}"},{key: "__esRouterSecondaryAdditionalConfig__", value: "{{es_router_additional_secondary_config}}"},{key: "__es_port__", value: "{{es_port}}"}, {key: "__keyspace_name__", value: "{{content_keyspace_name}}"}, {key: "__collection_fullecar_disable__", value: "{{collection_fullecar_disable}}"},{key: "__max_iteration_count_for_samza_job__", value: "{{max_iteration_count_for_samza_job}}"},{key: "__cloud_storage_type__", value: "{{cloud_store}}"},{key: "__azure_storage_key__", value: "{{azure_account_name}}"},{key: "__azure_storage_secret__", value: "{{azure_account_key}}"},{key: "__azure_storage_container__", value: "{{azure_public_container}}"},{key: "__content_media_base_url__", value: "{{content_media_base_url}}"}, {key: "__plugin_media_base_url__", value: "{{plugin_media_base_url}}"}, {key: "__installation_id__", value: "{{instance_name}}"}, {key: "__content_media_base_url__", value: "{{content_media_base_url}}"}, {key: "__hierarchy_keyspace_name__", value: "{{hierarchy_keyspace_name}}"},  {key: "__composite_search_indexer_container_count__", value: "{{composite_search_indexer_container_count}}"},{key: "__cassandra_lp_connection__", value: "{{lp_cassandra_connection}}"}, {key: "__cassandra_lpa_connection__", value: "{{dp_cassandra_connection}}"}, {key: "__streaming_mime_type__", value: "{{streaming_mime_type}}"}, {key: "__cassandra_sunbird_connection__", value: "{{core_cassandra_connection}}"}, {key: "__cloud_upload_retry_count__", value: "{{cloud_upload_retry_count}}"}, {key: "__compositesearch_index_name__", value: "{{compositesearch_index_name}}"},{key: "__publish_pipeline_container_count__", value: "{{publish_pipeline_container_count}}"},{key: "__yarn_container_memory_mb__", value: "{{publish_yarn_container_memory_mb}}"},{key: "__youtube_api_key__", value: "{{youtube_api_key}}"},{key: "__kp_learning_service_base_url__", value: "{{kp_learning_service_base_url}}"},{key: "__sunbird_installation__", value: "{{sunbird_platform_installation}}"},  {key: "__search_lms_es_host__", value: "{{search_lms_es_host}}"},{key: "__dial_image_storage_container__", value: "{{dial_image_storage_container}}"},{key: "__dial_base_url__", value: "{{dial_base_url}}"},{key: "__learner_service_base_url__", value: "{{learner_service_base_url}}"},{key: "__cert_service_base_url__", value: "{{cert_service_base_url}}"},{key: "__certificate_base_path__", value: "{{certificate_base_path}}"},{key: "__kp_content_service_base_url__", value: "{{kp_content_service_base_url}}"},{key: "__kp_print_service_base_url__", value: "{{kp_print_service_base_url}}"},{key: "__cert_reg_service_base_url__", value: "{{cert_reg_service_base_url}}"}]
    - "{{ (config_files|default({})).results|default([]) }}"


- name: Create directory for additional config
  file: path={{object_denormalization_additional_config_dir}} owner=hduser group=hadoop recurse=yes state=directory

- name: Update status of new jobs in file
  command: bash -lc "./update_new_job_name.sh {{job_status_file}} {{samza_jobs_dir}}/extract/{{item.item | basename}}"
  args:
    chdir: "{{samza_jobs_dir}}/extract/"
  when: "{{item|changed}}"
  with_items: "{{ (new_jobs|default({})).results|default([]) }}"

- name: Kill jobs
  command: bash -lc "./kill_jobs.sh {{job_status_file}}"
  args:
    chdir: /usr/local/hadoop/bin

- name: Start jobs
  command: bash -lc "./start_jobs.sh {{job_status_file}} {{samza_jobs_dir}}/extract"
  args:
    chdir: "{{samza_jobs_dir}}/extract/"
  become_user: hduser

- name: Remove all old tar
  command: bash -lc "./remove_old_tar.sh {{job_status_file}} {{samza_jobs_dir}}"
  args:
    chdir: "{{samza_jobs_dir}}/extract/"

- file: path={{samza_jobs_dir}} owner=hduser group=hadoop state=directory recurse=yes
