namespace: {{ flink_namespace }}
imagepullsecrets: {{ imagepullsecrets }}
dockerhub: {{ dockerhub }}
repository: {{flink_repository|default('knowledge-platform-jobs')}}
image_tag: {{ image_tag }}
azure_account: {{ azure_account }}
azure_secret: {{ azure_secret }}
serviceMonitor:
  enabled: {{ service_monitor_enabled | lower}}

replicaCount: {{taskmana_replicacount|default(1)}}

jobmanager:
  rpc_port: {{ jobmanager_rpc_port }}
  blob_port: {{ jobmanager_blob_port }}
  query_port: {{ jobmanager_query_port }}
  ui_port: {{ jobmanager_ui_port }}
  prom_port: {{ jobmanager_prom_port }}
  heap_memory: {{ jobmanager_heap_memory }}

service: {{ jobmanager_ui_service|to_json }}

rest_port: {{ jobmanager_ui_rest_port }}
resttcp_port: {{ jobmanager_ui_tcp_port }}

taskmanager:
  prom_port: {{ taskmanager_prom_port }}
  rpc_port: {{ taskmanager_rpc_port }}
  heap_memory: {{ taskmanager_heap_memory }}
  replicas: {{taskmanager_replicacount|default(1)}}

job_classname: {{ job_classname }}
{{ taskmanager_liveness | to_nice_yaml }}

log4j_console_properties: |
  # This affects logging for both user code and Flink
  rootLogger.level = {{ flink_jobs_console_log_level | default(INFO) }}
  rootLogger.appenderRef.console.ref = ConsoleAppender

  # Uncomment this if you want to _only_ change Flink's logging
  #logger.flink.name = org.apache.flink
  #logger.flink.level = {{ flink_jobs_console_log_level | default(INFO) }}

  # The following lines keep the log level of common libraries/connectors on
  # log level INFO. The root logger does not override this. You have to manually
  # change the log levels here.
  logger.akka.name = akka
  logger.akka.level = {{ flink_libraries_log_level | default(INFO) }}
  logger.kafka.name= org.apache.kafka
  logger.kafka.level = {{ flink_libraries_log_level | default(INFO) }}
  logger.hadoop.name = org.apache.hadoop
  logger.hadoop.level = {{ flink_libraries_log_level | default(INFO) }}
  logger.zookeeper.name = org.apache.zookeeper
  logger.zookeeper.level = {{ flink_libraries_log_level | default(INFO) }}

  # Log all infos to the console
  appender.console.name = ConsoleAppender
  appender.console.type = CONSOLE
  appender.console.layout.type = PatternLayout
  appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

  # Suppress the irrelevant (wrong) warnings from the Netty channel handler
  logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
  logger.netty.level = OFF

base_config: |
  kafka {
      broker-servers = "{{ kafka_brokers }}"
      zookeeper = "{{ zookeepers }}"
      producer {
        max-request-size = {{ producer_max_request_size }}
      }
    }
    job {
      env = "{{ env_name }}"
      enable.distributed.checkpointing = true
      statebackend {
        blob {
          storage {
            account = "{{ azure_account }}.blob.core.windows.net"
            container = "{{ flink_container_name }}"
            checkpointing.dir = "checkpoint"
          }
        }
        base.url = "wasbs://"${job.statebackend.blob.storage.container}"@"${job.statebackend.blob.storage.account}"/"${job.statebackend.blob.storage.checkpointing.dir}
      }
    }
    task {
      parallelism = 1
      consumer.parallelism = 1
      checkpointing.compressed = {{ checkpoint_compression_enabled|lower }}
      checkpointing.interval = {{ checkpoint_interval }}
      checkpointing.pause.between.seconds = {{ checkpoint_pause_between_seconds }}
      restart-strategy.attempts = {{ restart_attempts }}
      restart-strategy.delay = {{ restart_delay }} # in milli-seconds
    }
    redis {
      host = {{ dp_redis_host }}
      port = 6379
    }
    lms-cassandra {
      host = "{{ core_cassandra_connection_ip }}"
      port = "9042"
    }
    neo4j {
      routePath = "{{ neo4j_route_path }}"
      graph = "domain"
    }
    es {
        basePath = "{{ search_es_host }}"
    }
    schema {
      basePath = "{{ kp_schema_base_path }}"
      supportedVersion = {
        itemset = "2.0"
      }
    }

activity-aggregate-updater:
  activity-aggregate-updater: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.coursebatch.job.request
      output.audit.topic = {{ env_name }}.telemetry.raw
      output.failed.topic = {{ env_name }}.activity.agg.failed
      output.certissue.topic = {{ env_name }}.issue.certificate.request
      groupId = {{ env_name }}-activity-aggregate-group
    }
    task {
      window.shards = {{ activity_agg_window_shards }}
      checkpointing.interval = {{ activity_agg_checkpointing_interval }}
      checkpointing.pause.between.seconds = {{ activity_agg_checkpointing_pause_interval }}
      restart-strategy.attempts = {{ restart_attempts }} # max 3 restart attempts
      restart-strategy.delay = 240000 # in milli-seconds # on max restarts (3) within 4 min the job will fail.
      consumer.parallelism = {{ activity_agg_consumer_parallelism }}
      dedup.parallelism = {{ activity_agg_dedup_parallelism }}
      activity.agg.parallelism = {{ activity_agg_parallelism }}
      enrolment.complete.parallelism = {{ enrolment_complete_parallelism }}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      consumption.table = "{{ middleware_consumption_table }}"
      user_activity_agg.table = "{{ middleware_user_activity_agg_table }}"
      user_enrolments.table = "user_enrolments"
    }
    redis {
      database {
        relationCache.id = 10
      }
    }
    dedup-redis {
      host = {{ dedup_redis_host }}
      port = 6379
      database.index = {{ activity_agg_dedup_index }}
      database.expiry = {{ activity_agg_dedup_expiry }}
    }
    threshold.batch.read.interval = {{ activity_agg_batch_interval }}
    threshold.batch.read.size = {{ activity_agg_batch_read_size }}
    threshold.batch.write.size = {{ activity_agg_batch_write_size }}
    activity {
      module.aggs.enabled = true
      input.dedup.enabled = true
      filter.processed.enrolments = {{ activity_agg_enrolment_filter_processe_enabled | lower }}
      collection.status.cache.expiry = {{ activity_agg_collection_status_cache_expiry_time }}
    }
    service {
      search.basePath = "{{ kp_search_service_base_url }}"
    }


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['activity-aggregate-updater'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['activity-aggregate-updater'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['activity-aggregate-updater'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

relation-cache-updater:
  relation-cache-updater: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.content.postpublish.request
      groupId = {{ env_name }}-relation-cache-updater-group
    }
    task {
      consumer.parallelism = {{ relation_cache_updater_consumer_parallelism }}
      parallelism = {{ relation_cache_updater_parallelism }}
    }
    lms-cassandra {
          keyspace = "{{ middleware_hierarchy_keyspace }}"
          table = "{{ middleware_content_hierarchy_table }}"
    }
    redis {
      database.index = 10
    }
    dp-redis {
      host = {{ dp_redis_host }}
      port = 6379
      database.index = 5
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['relation-cache-updater'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['relation-cache-updater'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['relation-cache-updater'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

post-publish-processor:
  post-publish-processor: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.content.postpublish.request
      groupId = {{ env_name }}-post-publish-processor-group
      publish.topic = {{ env_name }}.publish.job.request
      qrimage.topic = {{ env_name }}.qrimage.request
      dialcode.context.topic = {{ env_name }}.dialcode.context.job.request
    }
    task {
      consumer.parallelism = {{ post_publish_processor_consumer_parallelism }}
      router.parallelism = {{ post_publish_event_router_parallelism }}
      shallow_copy.parallelism = {{ post_publish_shallow_copy_parallelism }}
      link_dialcode.parallelism = {{ post_publish_link_dialcode_parallelism }}
      batch_create.parallelism = {{ post_publish_batch_create_parallelism }}
      dialcode_context_updater.parallelism = {{ post_publish_dialcode_context_parallelism }}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      batchTable = "course_batch"
    }
    dialcode-cassandra {
      keyspace = "dialcodes"
      imageTable = "dialcode_images"
    }
    service {
      search.basePath = "{{ kp_search_service_base_url }}"
      lms.basePath = "{{ lms_service_base_url }}"
      learning_service.basePath = "{{ kp_learning_service_base_url }}"
      dial.basePath = "https://{{domain_name}}/dial/"
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['post-publish-processor'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['post-publish-processor'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['post-publish-processor'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

questionset-publish:
  questionset-publish: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.assessment.publish.request
      post_publish.topic = {{ env_name }}.content.postpublish.request
      groupId = {{ env_name }}-questionset-publish-group
    }
    task {
      consumer.parallelism = 1
      parallelism = 1
      router.parallelism = 1
    }
    question {
      keyspace = "{{ assessment_keyspace_name }}"
      table = "question_data"
    }
    questionset {
      keyspace = "{{ hierarchy_keyspace_name }}"
      table = "questionset_hierarchy"
    }
    print_service.base_url = "{{ kp_print_service_base_url }}"
    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

    master.category.validation.enabled ="{{ master_category_validation_enabled }}"

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['questionset-publish'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['questionset-publish'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['questionset-publish'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

video-stream-generator:
  video-stream-generator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.content.postpublish.request"
      groupId = "{{ env_name }}-video-stream-generator-group"
    }
    task {
      timer.duration = {{ video_stream_generator_timer_duration }}
      consumer.parallelism = {{ video_stream_generator_consumer_parallelism }}
      parallelism = {{ video_stream_generator_parallelism }}
      max.retries = {{ video_stream_generator_max_retries }}
    }
    lms-cassandra {
      keyspace = {{ platform_keyspace_name }}
      table = "job_request"
    }
    service.content.basePath="{{ kp_content_service_base_url }}"
    azure {
      location = "centralindia"
      login {
        endpoint="https://login.microsoftonline.com"
      }
      api {
        endpoint="https://management.azure.com"
        version = "2018-07-01"
      }
      transform {
        default = "media_transform_default"
        hls = "media_transform_hls"
      }
      stream {
        base_url="{{ video_stream_generator_azure_stream_base_url }}"
        endpoint_name = "default"
        protocol = "Hls"
        policy_name = "Predefined_ClearStreamingOnly"
      }
    }
    azure_tenant="{{ video_stream_generator_azure_tenant }}"
    azure_subscription_id="{{ video_stream_generator_azure_subscription_id }}"
    azure_account_name="{{ video_stream_generator_azure_account_name }}"
    azure_resource_group_name="{{ video_stream_generator_azure_resource_group_name }}"
    azure_token_client_key="{{ video_stream_generator_azure_token_client_key }}"
    azure_token_client_secret="{{ video_stream_generator_azure_token_client_secret }}"
    ## CSP Name. e.g: aws or azure
    media_service_type="{{ media_service_provider_name }}"
    ## AWS Elemental Media Convert Config
    aws {
      region="{{ aws_mediaconvert_region }}"
      content_bucket_name="{{ aws_content_bucket_name }}"
      token {
        access_key="{{ aws_mediaconvert_access_key }}"
        access_secret="{{ aws_mediaconvert_access_secret }}"
      }
      api {
        endpoint="{{ aws_mediaconvert_api_endpoint }}"
        version="{{ aws_mediaconvert_api_version }}"
      }
      service {
        name="mediaconvert"
        queue="{{ aws_mediaconvert_queue_id }}"
        role="{{ aws_mediaconvert_role_name }}"
      }
      stream {
        protocol="Hls"
      }
    }


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['video-stream-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

search-indexer:
  search-indexer: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.learning.graph.events"
      error.topic = "{{ env_name }}.learning.events.failed"
      groupId = "{{ env_name }}-search-indexer-group"
    }
    task {
      consumer.parallelism = {{ search_indexer_consumer_parallelism }}
      router.parallelism = {{ transaction_event_router_parallelism }}
      compositeSearch.parallelism = {{ composite_search_indexer_parallelism }}
      dialcodeIndexer.parallelism = {{ dialcode_external_indexer_parallelism }}
      dialcodemetricsIndexer.parallelism = {{ dialcode_metric_indexer_parallelism }}
    }
    compositesearch.index.name = "compositesearch"
    dialcode.index.name = "dialcode"
    dailcodemetrics.index.name = "dialcodemetrics"
    restrict.metadata.objectTypes = []
    nested.fields = ["badgeAssertions", "targets", "badgeAssociations", "plugins", "me_totalTimeSpent", "me_totalPlaySessionCount", "me_totalTimeSpentInSec", "batches", "trackable", "credentials", "discussionForum", "provider", "osMetadata", "actions", "transcripts", "accessibility"]
    schema.definition_cache.expiry = {{ schema_definition_cache_expiry_in_sec }}
    restrict.objectTypes = {{ search_indexer_restrict_object_types | to_json }}
    ignored.fields={{ search_indexer_ignored_fields | to_json }}

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['search-indexer'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['search-indexer'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['search-indexer'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

enrolment-reconciliation:
  enrolment-reconciliation: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.batch.enrolment.sync.request
      output.audit.topic = {{ env_name }}.telemetry.raw
      output.failed.topic = {{ env_name }}.activity.agg.failed
      output.certissue.topic = {{ env_name }}.issue.certificate.request
      groupId = {{ env_name }}-enrolment-reconciliation-group
    }
    task {
      restart-strategy.attempts = {{ restart_attempts }} # max 3 restart attempts
      restart-strategy.delay = 240000 # in milli-seconds # on max restarts (3) within 4 min the job will fail.
      consumer.parallelism = {{ enrolment_reconciliation_consumer_parallelism }}
      enrolment.reconciliation.parallelism = {{ enrolment_reconciliation_parallelism }}
      enrolment.complete.parallelism = {{ enrolment_complete_parallelism }}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      consumption.table = "{{ middleware_consumption_table }}"
      user_activity_agg.table = "{{ middleware_user_activity_agg_table }}"
      user_enrolments.table = "user_enrolments"
    }
    redis {
      database {
        relationCache.id = 10
      }
    }
    threshold.batch.write.size = {{ enrolment_reconciliation_batch_write_size }}
    activity {
      module.aggs.enabled = true
      collection.status.cache.expiry = {{ enrolment_reconciliation_collection_status_cache_expiry_time }}
    }
    service {
      search.basePath = "{{ kp_search_service_base_url }}"
    }


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['enrolment-reconciliation'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['enrolment-reconciliation'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['enrolment-reconciliation'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

asset-enrichment:
  asset-enrichment: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.learning.job.request
      groupId = {{ env_name }}-asset-enrichment-group
      video_stream.topic = {{ env_name }}.content.postpublish.request
    }
    task {
      checkpointing.timeout = 900000
      checkpointing.interval = {{ asset_enrichment_checkpointing_interval }}
      checkpointing.pause.between.seconds = {{ asset_enrichment_checkpointing_pause_interval }}
      consumer.parallelism = {{ asset_enrichment_consumer_parallelism }}
      router.parallelism = {{ asset_enrichment_router_parallelism }}
      imageEnrichment.parallelism = {{ image_enrichment_parallelism }}
      videoEnrichment.parallelism = {{ video_enrichment_parallelism }}
    }
    content {
      stream {
        enabled = true
        mimeType = ["video/mp4", "video/webm"]
      }
      youtube {
        applicationName = "fetch-youtube-license"
        regexPattern = ["\\?vi?=([^&]*)", "watch\\?.*v=([^&]*)", "(?:embed|vi?)/([^/?]*)", "^([A-Za-z0-9\\-\\_]*)"]
      }
      upload.context.driven = true
      max.iteration.count = 2
    }
    thumbnail.max {
      sample = 5
      size.pixel = 150
    }
    content_youtube_apikey="{{ youtube_api_key }}"
    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['asset-enrichment'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['asset-enrichment'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['asset-enrichment'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

audit-history-indexer:
  audit-history-indexer: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.learning.graph.events"
      groupId = "{{ env_name }}-audit-history-indexer-group"
    }

    task {
      consumer.parallelism = {{ audit_history_indexer_consumer_parallelism }}
      parallelism = {{ audit_history_indexer_parallelism }}
      window.time = 60
    }

    timezone = "IST"

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['audit-history-indexer'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['audit-history-indexer'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['audit-history-indexer'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

auto-creator-v2:
  auto-creator-v2: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.object.import.request"
      groupId = "{{ env_name }}-auto-creator-v2-group"
    }

    task {
      consumer.parallelism = {{ auto_creator_v2_consumer_parallelism }}
      parallelism = {{ auto_creator_v2_parallelism }}
      window.time = 60
    }

    question {
      keyspace = "{{ assessment_keyspace_name }}"
    }
    questionset {
      keyspace = "{{ hierarchy_keyspace_name }}"
    }
    service {
      content.basePath = "{{ kp_content_service_base_url }}"
    }
    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

    source {
      baseUrl="{{ source_base_url }}"
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['auto-creator-v2'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['auto-creator-v2'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['auto-creator-v2'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1


content-auto-creator:
  content-auto-creator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.auto.creation.job.request"
      groupId = "{{ env_name }}-content-auto-creator-group"
      failed.topic = "{{ env_name }}.auto.creation.job.request.failed"
    }

    task {
      consumer.parallelism = {{ content_auto_creator_consumer_parallelism }}
      parallelism = {{ content_auto_creator_parallelism }}
      window.time = 60
      checkpointing.timeout = 4200000
    }

    redis {
      database {
        relationCache.id = 10
        collectionCache.id = 5
      }
    }

    service {
      content_service.basePath = "{{ kp_content_service_base_url }}"
      search.basePath = "{{ kp_search_service_base_url }}"
      lms.basePath = "{{ lms_service_base_url }}"
      learning_service.basePath = "{{ kp_learning_service_base_url }}"
    }

    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

    content_auto_creator {
        actions=auto-create
        allowed_object_types=["Content"]
        allowed_content_stages=["create","upload","review","publish"]
        content_mandatory_fields=["name","code","mimeType","primaryCategory","artifactUrl","lastPublishedBy"]
        content_props_to_removed=["identifier","downloadUrl","variants","createdOn","collections","children","lastUpdatedOn","SYS_INTERNAL_LAST_UPDATED_ON","versionKey","s3Key","status","pkgVersion","toc_url","mimeTypesCount","contentTypesCount","leafNodesCount","childNodes","prevState","lastPublishedOn","flagReasons","compatibilityLevel","size","publishChecklist","publishComment","lastPublishedBy","rejectReasons","rejectComment","badgeAssertions","leafNodes","sYS_INTERNAL_LAST_UPDATED_ON","previewUrl","channel","objectType","visibility","version","pragma","prevStatus","streamingUrl","idealScreenSize","contentDisposition","lastStatusChangedOn","idealScreenDensity","lastSubmittedOn","publishError","flaggedBy","flags","lastFlaggedOn","publisher","lastUpdatedBy","lastSubmittedBy","uploadError","lockKey","publish_type","reviewError","totalCompressedSize","origin","originData","importError","questions"]
        bulk_upload_mime_types=["video/mp4"]
        artifact_upload_max_size=157286400
        content_create_props=["name","code","mimeType","contentType","framework","processId","primaryCategory"]
        artifact_upload_allowed_source=[]
        g_service_acct_cred="{{ auto_creator_g_service_acct_cred }}"
        gdrive.application_name=drive-download
        initial_backoff_delay=120000
        maximum_backoff_delay=1200000
        increment_backoff_delay=2
        api_call_delay=1
        maxIteration=1
    }

    search_exists_fields=["originData"]
    search_fields=["identifier","mimeType","pkgVersion","channel","status","origin","originData","artifactUrl"]


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['content-auto-creator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['content-auto-creator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['content-auto-creator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1


audit-event-generator:
  audit-event-generator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.learning.graph.events"
      output.topic = "{{ env_name }}.telemetry.raw"
      groupId = "{{ env_name }}-audit-event-generator-group"
    }

    task {
      consumer.parallelism = {{ audit_event_generator_consumer_parallelism }}
      parallelism = {{ audit_event_generator_parallelism }}
      producer.parallelism = {{ audit_event_generator_producer_parallelism }}
    }

    schema {
      basePath = "{{ kp_schema_base_path }}"
    }

    channel.default = "{{ audit_event_generator_default_channel }}"


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['audit-event-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['audit-event-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['audit-event-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

metrics-data-transformer:
  metrics-data-transformer: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.learning.graph.events
      groupId = {{ env_name }}-metrics-data-transformer-group
    }

    task {
      consumer.parallelism = {{ metrics_data_transformer_consumer_parallelism }}
      parallelism = {{ metrics_data_transformer_parallelism }}
      producer.parallelism = {{ metrics_data_transformer_producer_parallelism }}
    }
    content_read_api = "/content/v3/read"
    content_update_api = "/content/v4/system/update"
    service {
      content.basePath = "{{ kp_content_service_base_url }}"
      sourcing.content.basePath = "{{ sourcing_content_service_base_url }}"
    }
    sourcing.update.api.response.error.code = ["404", "400"]
    data.metrics = ["me_totalRatingsCount","me_averageRating","me_totalTimeSpentInSec","me_totalPlaySessionCount"]

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['metrics-data-transformer'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['metrics-data-transformer'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['metrics-data-transformer'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

collection-cert-pre-processor:
  collection-cert-pre-processor: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.issue.certificate.request
      output.topic = {{ env_name }}.generate.certificate.request
      output.failed.topic = {{ env_name }}.issue.certificate.failed
      groupId = {{ env_name }}-collection-cert-pre-processor-group
    }
    task {
      restart-strategy.attempts = {{ restart_attempts }} # max 3 restart attempts
      restart-strategy.delay = 240000 # in milli-seconds # on max restarts (3) within 4 min the job will fail.
      parallelism = {{collection_cert_pre_processor_consumer_parallelism}}
      consumer.parallelism = {{ collection_cert_pre_processor_consumer_parallelism }}
      generate_certificate.parallelism = {{generate_certificate_parallelism}}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      consumption.table = "{{ middleware_consumption_table }}"
      user_enrolments.table = "{{ middleware_user_enrolments_table }}"
      course_batch.table = "{{ middleware_course_batch_table }}"
      assessment_aggregator.table = "{{ middleware_assessment_aggregator_table }}"
      user_activity_agg.table = "{{ middleware_user_activity_agg_table }}"
    }
    cert_domain_url = "{{ cert_domain_url }}"
    user_read_api = "/private/user/v1/read"
    content_read_api = "/content/v3/read"
    service {
      content.basePath = "{{ content_service_base_url }}"
      learner.basePath = "{{ learner_service_base_url }}"
    }
    enable.suppress.exception = {{ collection_certificate_pre_processor_enable_suppress_exception | lower }}
    redis-meta {
    {% if metadata2_redis_host is defined %}
      host = {{ metadata2_redis_host }}
    {% else %}
      host = {{ redis_host }}
    {% endif %}
      port = 6379
    }
    assessment.metrics.supported.contenttype = ["SelfAssess"]

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['collection-cert-pre-processor'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['collection-cert-pre-processor'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['collection-cert-pre-processor'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    
collection-certificate-generator:
  collection-certificate-generator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.generate.certificate.request
      output.audit.topic = {{ env_name }}.telemetry.raw
      groupId = {{ env_name }}-certificate-generator-group
    }
    task {
      restart-strategy.attempts = {{ restart_attempts }} # max 3 restart attempts
      restart-strategy.delay = 240000 # in milli-seconds # on max restarts (3) within 4 min the job will fail.
      consumer.parallelism = {{ collection_certificate_generator_consumer_parallelism }}
      parallelism = {{ collection_certificate_generator_parallelism }}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      user_enrolments.table = "{{ middleware_user_enrolments_table }}"
      course_batch.table = "{{ middleware_course_batch_table }}"
      sbkeyspace = "{{ registry_sunbird_keyspace }}"
      certreg.table ="{{ cert_registry_table }}"
    }
    cert_domain_url = "{{ cert_domain_url }}"
    cert_container_name = "{{ cert_container_name }}"
    cert_cloud_storage_type = "{{ cert_cloud_storage_type }}"
    cert_azure_storage_secret = "{{ cert_azure_storage_secret }}"
    cert_azure_storage_key = "{{ cert_azure_storage_key }}"
    service {
      certreg.basePath = "{{ cert_reg_service_base_url }}"
      learner.basePath = "{{ learner_service_base_url }}"
      enc.basePath = "{{ enc_service_base_url }}"
      rc.basePath = "{{ cert_rc_base_url }}"
      rc.entity = "{{ cert_rc_entity }}"
    }
    enable.suppress.exception = {{ collection_certificate_generator_enable_suppress_exception | lower }}
    enable.rc.certificate = {{ collection_certificate_generator_enable_rc_certificate | lower }}
    task.rc.badcharlist = {{ collection_certificate_generator_rc_badcharlist }}


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['collection-certificate-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['collection-certificate-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['collection-certificate-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

mvc-indexer:
  mvc-indexer: |+
    include "base-config.conf"

    kafka {
      input.topic = "{{ env_name }}.mvc.processor.job.request"
      groupId = "{{ env_name }}-mvc-indexer-group"
      output.failed.topic = "{{ env_name }}.mvc.events.failed"
    }

    task {
      consumer.parallelism = {{ mvc_indexer_consumer_parallelism }}
      parallelism = {{ mvc_indexer_parallelism }}
    }

    lms-cassandra.keyspace = "{{ content_keyspace_name }}"
    lms-cassandra.table = "content_data"

    nested.fields="{{ mvc_indexer_nested_fields }}"

    service.content.basePath = "{{ kp_content_service_base_url }}"
    es.indexAlias = "mvc-content"

    ml.vector.host="{{ mvc_indexer_ml_vector_host }}"
    ml.vector.port="{{ mvc_indexer_ml_vector_port }}"
    ml.keyword.host="{{ mvc_indexer_ml_keyword_host }}"
    ml.keyword.port="{{ mvc_indexer_ml_keyword_port }}"


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['mvc-indexer'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['mvc-indexer'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['mvc-indexer'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

content-publish:
  content-publish: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.publish.job.request
      post_publish.topic = {{ env_name }}.content.postpublish.request
      mvc.topic = "{{ env_name }}.mvc.processor.job.request"
      error.topic = "{{ env_name }}.learning.events.failed"
      groupId = {{ env_name }}-content-publish-group
    }
    task {
      consumer.parallelism = 1
      parallelism = 1
      router.parallelism = 1
    }
    redis {
      host={{redis_host}}
      port=6379
      database {
        contentCache.id = 0
      }
    }
    content {
      bundleLocation = "/tmp/contentBundle"
      isECARExtractionEnabled = true
      retry_asset_download_count = 1
      keyspace = "{{ content_keyspace_name }}"
      table = "content_data"
      tmp_file_location = "/tmp"
      objectType = ["Content", "ContentImage","Collection","CollectionImage"]
      mimeType = ["application/pdf",
                                   "application/vnd.ekstep.ecml-archive",
                                   "application/vnd.ekstep.html-archive",
                                   "application/vnd.android.package-archive",
                                   "application/vnd.ekstep.content-archive",
                                   "application/epub",
                                   "application/msword",
                                   "application/vnd.ekstep.h5p-archive",
                                   "video/webm",
                                   "video/mp4",
                                   "application/vnd.ekstep.content-collection",
                                   "video/quicktime",
                                   "application/octet-stream",
                                   "application/json",
                                   "application/javascript",
                                   "application/xml",
                                   "text/plain",
                                   "text/html",
                                   "text/javascript",
                                   "text/xml",
                                   "text/css",
                                   "image/jpeg",
                                   "image/jpg",
                                   "image/png",
                                   "image/tiff",
                                   "image/bmp",
                                   "image/gif",
                                   "image/svg+xml",
                                   "image/x-quicktime",
                                   "video/avi",
                                   "video/mpeg",
                                   "video/quicktime",
                                   "video/3gpp",
                                   "video/mp4",
                                   "video/ogg",
                                   "video/webm",
                                   "video/msvideo",
                                   "video/x-msvideo",
                                   "video/x-qtc",
                                   "video/x-mpeg",
                                   "audio/mp3",
                                   "audio/mp4",
                                   "audio/mpeg",
                                   "audio/ogg",
                                   "audio/webm",
                                   "audio/x-wav",
                                   "audio/wav",
                                   "audio/mpeg3",
                                   "audio/x-mpeg-3",
                                   "audio/vorbis",
                                   "application/x-font-ttf",
                                   "application/vnd.ekstep.plugin-archive",
                                   "video/x-youtube",
                                   "video/youtube",
                                   "text/x-url"]
      asset_download_duration = "60 seconds"
      stream {
        enabled = {{ content_stream_enabled | lower }}
        mimeType = ["video/mp4", "video/webm"]
      }
      artifact.size.for_online= {{ content_artifact_size_for_online }}

      downloadFiles {
        spine = ["appIcon"]
        full = ["appIcon", "grayScaleAppIcon", "artifactUrl", "itemSetPreviewUrl", "media"]
      }

      nested.fields=["badgeAssertions", "targets", "badgeAssociations", "plugins", "me_totalTimeSpent", "me_totalPlaySessionCount", "me_totalTimeSpentInSec", "batches", "trackable", "credentials", "discussionForum", "provider", "osMetadata", "actions", "transcripts", "accessibility"]

    }
    cloud_storage {
        folder {
            content = "content"
            artifact = "artifact"
        }
    }

    hierarchy {
      keyspace = "{{ hierarchy_keyspace_name }}"
      table = "content_hierarchy"
    }

    contentTypeToPrimaryCategory {
      ClassroomTeachingVideo: "Explanation Content"
      ConceptMap: "Learning Resource"
      Course: "Course"
      CuriosityQuestionSet: "Practice Question Set"
      eTextBook: "eTextbook"
      Event: "Event"
      EventSet: "Event Set"
      ExperientialResource: "Learning Resource"
      ExplanationResource: "Explanation Content"
      ExplanationVideo: "Explanation Content"
      FocusSpot: "Teacher Resource"
      LearningOutcomeDefinition: "Teacher Resource"
      MarkingSchemeRubric: "Teacher Resource"
      PedagogyFlow: "Teacher Resource"
      PracticeQuestionSet: "Practice Question Set"
      PracticeResource: "Practice Question Set"
      SelfAssess: "Course Assessment"
      TeachingMethod: "Teacher Resource"
      TextBook: "Digital Textbook"
      Collection: "Content Playlist"
      ExplanationReadingMaterial: "Learning Resource"
      LearningActivity: "Learning Resource"
      LessonPlan: "Content Playlist"
      LessonPlanResource: "Teacher Resource"
      PreviousBoardExamPapers: "Learning Resource"
      TVLesson: "Explanation Content"
      OnboardingResource: "Learning Resource"
      ReadingMaterial: "Learning Resource"
      Template: "Template"
      Asset: "Asset"
      Plugin: "Plugin"
      LessonPlanUnit: "Lesson Plan Unit"
      CourseUnit: "Course Unit"
      TextBookUnit: "Textbook Unit"
      Asset: "Certificate Template"
    }

    compositesearch.index.name = "compositesearch"
    search.document.type = "cs"
    enableDIALContextUpdate = "Yes"

    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

    master.category.validation.enabled ="{{ master_category_validation_enabled }}"
    service {
      print.basePath = "{{ kp_print_service_base_url }}"
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['content-publish'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['content-publish'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['content-publish'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

qrcode-image-generator:
  qrcode-image-generator: |+
    include file("/data/flink/conf/base-config.conf")

    kafka {
      input.topic = "{{ env_name }}.qrimage.request"
      groupId = "{{ env_name }}-qrcode-image-generator-group"
    }

    task {
      consumer.parallelism = {{ qrcode_image_generator_consumer_parallelism }}
      parallelism = {{ qrcode_image_generator_parallelism }}
      window.time = 60
    }

    lp.tmp.file.location="/tmp"

    qr.image {
        imageFormat="png"
        bottomMargin=0
        margin=1
    }

    cloud_storage_type="{{ cloud_store }}"
    cloud_storage_key="{{ cloud_storage_key }}"
    cloud_storage_secret="{{ cloud_storage_secret }}"
    cloud_storage_container="{{ cloud_storage_container }}"

    lms-cassandra {
      keyspace = "dialcodes"
      table {
        image = "dialcode_images"
        batch = "dialcode_batch"
      }
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['qrcode-image-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['qrcode-image-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['qrcode-image-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

dialcode-context-updater:
  dialcode-context-updater: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.dialcode.context.job.request"
      failed.topic = "{{ env_name }}.dialcode.context.job.request.failed"
      groupId = "{{ env_name }}-dialcode-group"
    }
    task {
      consumer.parallelism = 1
      parallelism = 1
      dialcode-context-updater.parallelism = 1
    }
    dialcode_context_updater {
      actions="dialcode-context-update"
      search_mode="Collection"
      context_map_path = "https://raw.githubusercontent.com/project-sunbird/knowledge-platform-jobs/release-5.0.0/dialcode-context-updater/src/main/resources/contextMapping.json"
      identifier_search_fields = ["identifier", "primaryCategory", "channel"]
      dial_code_context_read_api_path = "/dialcode/v4/read/"
      dial_code_context_update_api_path = "/dialcode/v4/update/"
    }
    service {
      search.basePath = "{{ kp_search_service_base_url }}"
      dial_service.basePath = "{{ kp_dial_service_base_url }}"
    }

    es_sync_wait_time = 20000

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['qrcode-image-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['qrcode-image-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['qrcode-image-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

live-node-publisher:
  live-node-publisher: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.republish.job.request
      live_video_stream.topic = "{{ env_name }}.live.video.stream.request"
      error.topic = "{{ env_name }}.learning.events.failed"
      skipped.topic = "{{ env_name }}.learning.events.skipped"
      groupId = {{ env_name }}-content-republish-group
    }
    task {
      consumer.parallelism = 1
      parallelism = 1
      router.parallelism = 1
    }
    redis {
      host={{redis_host}}
      port=6379
      database {
        contentCache.id = 0
      }
    }
    content {
      bundleLocation = "/tmp/contentBundle"
      isECARExtractionEnabled = true
      retry_asset_download_count = 1
      keyspace = "{{ content_keyspace_name }}"
      table = "content_data"
      tmp_file_location = "/tmp"
      objectType = ["Content", "ContentImage","Collection","CollectionImage"]
      mimeType = ["application/pdf",
                   "application/vnd.ekstep.ecml-archive",
                   "application/vnd.ekstep.html-archive",
                   "application/vnd.android.package-archive",
                   "application/vnd.ekstep.content-archive",
                   "application/epub",
                   "application/msword",
                   "application/vnd.ekstep.h5p-archive",
                   "video/webm",
                   "video/mp4",
                   "application/vnd.ekstep.content-collection",
                   "video/quicktime",
                   "application/octet-stream",
                   "application/json",
                   "application/javascript",
                   "application/xml",
                   "text/plain",
                   "text/html",
                   "text/javascript",
                   "text/xml",
                   "text/css",
                   "image/jpeg",
                   "image/jpg",
                   "image/png",
                   "image/tiff",
                   "image/bmp",
                   "image/gif",
                   "image/svg+xml",
                   "image/x-quicktime",
                   "video/avi",
                   "video/mpeg",
                   "video/quicktime",
                   "video/3gpp",
                   "video/mp4",
                   "video/ogg",
                   "video/webm",
                   "video/msvideo",
                   "video/x-msvideo",
                   "video/x-qtc",
                   "video/x-mpeg",
                   "audio/mp3",
                   "audio/mp4",
                   "audio/mpeg",
                   "audio/ogg",
                   "audio/webm",
                   "audio/x-wav",
                   "audio/wav",
                   "audio/mpeg3",
                   "audio/x-mpeg-3",
                   "audio/vorbis",
                   "application/x-font-ttf",
                   "application/vnd.ekstep.plugin-archive",
                   "video/x-youtube",
                   "video/youtube",
                   "text/x-url"]
      asset_download_duration = "60 seconds"
      stream {
        enabled = {{ content_stream_enabled | lower }}
        mimeType = ["video/mp4", "video/webm"]
      }
      artifact.size.for_online= {{ content_artifact_size_for_online }}

      downloadFiles {
        spine = ["appIcon"]
        full = ["appIcon", "grayScaleAppIcon", "artifactUrl", "itemSetPreviewUrl", "media"]
      }

      nested.fields=["badgeAssertions", "targets", "badgeAssociations", "plugins", "me_totalTimeSpent", "me_totalPlaySessionCount", "me_totalTimeSpentInSec", "batches", "trackable", "credentials", "discussionForum", "provider", "osMetadata", "actions", "transcripts", "accessibility"]

    }
    cloud_storage {
        folder {
            content = "content"
            artifact = "artifact"
        }
    }

    hierarchy {
      keyspace = "{{ hierarchy_keyspace_name }}"
      table = "content_hierarchy"
    }

    contentTypeToPrimaryCategory {
      ClassroomTeachingVideo: "Explanation Content"
      ConceptMap: "Learning Resource"
      Course: "Course"
      CuriosityQuestionSet: "Practice Question Set"
      eTextBook: "eTextbook"
      Event: "Event"
      EventSet: "Event Set"
      ExperientialResource: "Learning Resource"
      ExplanationResource: "Explanation Content"
      ExplanationVideo: "Explanation Content"
      FocusSpot: "Teacher Resource"
      LearningOutcomeDefinition: "Teacher Resource"
      MarkingSchemeRubric: "Teacher Resource"
      PedagogyFlow: "Teacher Resource"
      PracticeQuestionSet: "Practice Question Set"
      PracticeResource: "Practice Question Set"
      SelfAssess: "Course Assessment"
      TeachingMethod: "Teacher Resource"
      TextBook: "Digital Textbook"
      Collection: "Content Playlist"
      ExplanationReadingMaterial: "Learning Resource"
      LearningActivity: "Learning Resource"
      LessonPlan: "Content Playlist"
      LessonPlanResource: "Teacher Resource"
      PreviousBoardExamPapers: "Learning Resource"
      TVLesson: "Explanation Content"
      OnboardingResource: "Learning Resource"
      ReadingMaterial: "Learning Resource"
      Template: "Template"
      Asset: "Asset"
      Plugin: "Plugin"
      LessonPlanUnit: "Lesson Plan Unit"
      CourseUnit: "Course Unit"
      TextBookUnit: "Textbook Unit"
      Asset: "Certificate Template"
    }

    compositesearch.index.name = "compositesearch"
    search.document.type = "cs"
    enableDIALContextUpdate = "Yes"

    cloud_storage_type="{{ cloud_store }}"
    azure_storage_key="{{ sunbird_public_storage_account_name }}"
    azure_storage_secret="{{ sunbird_public_storage_account_key }}"
    azure_storage_container="{{ azure_public_container }}"

    master.category.validation.enabled ="{{ master_category_validation_enabled }}"
    service {
      print.basePath = "{{ kp_print_service_base_url }}"
      search.basePath = "{{ kp_search_service_base_url }}"
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['content-publish'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['content-publish'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['content-publish'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

live-video-stream-generator:
  live-video-stream-generator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.live.video.stream.request"
      groupId = "{{ env_name }}-live-video-stream-generator-group"
    }
    task {
      timer.duration = {{ video_stream_generator_timer_duration }}
      consumer.parallelism = {{ video_stream_generator_consumer_parallelism }}
      parallelism = {{ video_stream_generator_parallelism }}
      max.retries = {{ video_stream_generator_max_retries }}
    }
    lms-cassandra {
      keyspace = {{ platform_keyspace_name }}
      table = "job_request"
    }
    service.content.basePath="{{ kp_content_service_base_url }}"
    azure {
      location = "centralindia"
      login {
        endpoint="https://login.microsoftonline.com"
      }
      api {
        endpoint="https://management.azure.com"
        version = "2018-07-01"
      }
      transform {
        default = "media_transform_default"
        hls = "media_transform_hls"
      }
      stream {
        base_url="{{ video_stream_generator_azure_stream_base_url }}"
        endpoint_name = "default"
        protocol = "Hls"
        policy_name = "Predefined_ClearStreamingOnly"
      }
    }
    azure_tenant="{{ video_stream_generator_azure_tenant }}"
    azure_subscription_id="{{ video_stream_generator_azure_subscription_id }}"
    azure_account_name="{{ video_stream_generator_azure_account_name }}"
    azure_resource_group_name="{{ video_stream_generator_azure_resource_group_name }}"
    azure_token_client_key="{{ video_stream_generator_azure_token_client_key }}"
    azure_token_client_secret="{{ video_stream_generator_azure_token_client_secret }}"
    ## CSP Name. e.g: aws or azure
    media_service_type="{{ media_service_provider_name }}"
    ## AWS Elemental Media Convert Config
    aws {
      region="{{ aws_mediaconvert_region }}"
      content_bucket_name="{{ aws_content_bucket_name }}"
      token {
        access_key="{{ aws_mediaconvert_access_key }}"
        access_secret="{{ aws_mediaconvert_access_secret }}"
      }
      api {
        endpoint="{{ aws_mediaconvert_api_endpoint }}"
        version="{{ aws_mediaconvert_api_version }}"
      }
      service {
        name="mediaconvert"
        queue="{{ aws_mediaconvert_queue_id }}"
        role="{{ aws_mediaconvert_role_name }}"
      }
      stream {
        protocol="Hls"
      }
    }


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['video-stream-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

csp-migrator:
  csp-migrator: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = "{{ env_name }}.csp.migration.job.request"
      groupId = "{{ env_name }}-csp-migrator-group"
      failed.topic = "{{ env_name }}.csp.migration.job.request.failed"
      live_video_stream.topic = "{{ env_name }}.live.video.stream.request"
      live_content_node_republish.topic = "{{ env_name }}.republish.job.request"
    }
    task {
      timer.duration = {{ csp_migrator_timer_duration }}
      consumer.parallelism = {{ csp_migrator_consumer_parallelism }}
      parallelism = {{ csp_migrator_parallelism }}
      max.retries = {{ csp_migrator_max_retries }}
      cassandra-migrator.parallelism = {{csp_migrator_cassandra_parallelism}}
    }
    redis {
      database {
        relationCache.id = 10
        collectionCache.id = 5
      }
    }

    hierarchy {
      keyspace = "{{ hierarchy_keyspace_name }}"
      table = "content_hierarchy"
    }

    content {
        keyspace = "{{ content_keyspace_name }}"
        content_table = "content_data"
        assessment_table = "question_data"
    }

    key_value_strings_to_migrate = {
        "https://sunbirddev.blob.core.windows.net": "$Knowlg_Store$",
        "https://ekstep-public-dev.s3-ap-south-1.amazonaws.com": "$Knowlg_Store$",
        "https://community.ekstep.in/assets/public": "$Knowlg_Store$",
        "https://ntpproductionall.blob.core.windows.net/ntp-content-production": "$Knowlg_Store$",
        "https://vdn.diksha.gov.in/assets/public": "$Knowlg_Store$",
        "https://sunbirdstagingpublic.blob.core.windows.net/sunbird-content-staging": "$Knowlg_Store$"
    }

    neo4j_fields_to_migrate = {
        "asset": ["artifactUrl","thumbnail"],
        "content": ["appIcon","artifactUrl", "posterImage", "previewUrl", "thumbnail", "assetsMap", "certTemplate", "itemSetPreviewUrl", "grayScaleAppIcon", "sourceURL", "variants", "downloadUrl"],
        "contentimage": ["appIcon","artifactUrl", "posterImage", "previewUrl", "thumbnail", "assetsMap", "certTemplate", "itemSetPreviewUrl", "grayScaleAppIcon", "sourceURL", "variants", "downloadUrl"],
        "collection": ["appIcon","artifactUrl", "posterImage", "previewUrl", "thumbnail", "toc_url", "grayScaleAppIcon", "variants"],
        "collectionimage": ["appIcon","artifactUrl", "posterImage", "previewUrl", "thumbnail", "toc_url", "grayScaleAppIcon", "variants"],
        "plugins": ["artifactUrl"],
        "itemset": ["previewUrl"],
        "assessmentitem": ["data", "question", "solutions", "editorState", "media"]
    }

    cassandra_fields_to_migrate = {
        "assessmentitem": ["body", "editorState", "answer", "solutions", "instructions", "media"]
    }

    migrationVersion = 1
    video_stream_regeneration_enable = false
    live_node_republish_enable = true
    copy_missing_files_to_cloud = false
    download_path = /tmp


  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['video-stream-generator'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['video-stream-generator'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1