namespace: {{ flink_namespace }}
imagepullsecrets: {{ imagepullsecrets }}
dockerhub: {{ dockerhub }}
repository: {{flink_repository|default('knowledge-platform-jobs')}}
image_tag: {{ image_tag }}
azure_account: {{ azure_account }}
azure_secret: {{ azure_secret }}

replicaCount: {{taskmana_replicacount|default(1)}}

jobmanager:
  rpc_port: {{ jobmanager_rpc_port }}
  blob_port: {{ jobmanager_blob_port }}
  query_port: {{ jobmanager_query_port }}
  ui_port: {{ jobmanager_ui_port }}
  prom_port: {{ jobmanager_prom_port }}
  heap_memory: {{ jobmanager_heap_memory }}

service: {{ jobmanager_ui_service|to_json }}

rest_port: {{ jobmanager_ui_rest_port }}
resttcp_port: {{ jobmanager_ui_tcp_port }}

taskmanager:
  prom_port: {{ taskmanager_prom_port }}
  rpc_port: {{ taskmanager_rpc_port }}
  heap_memory: {{ taskmanager_heap_memory }}
  replicas: {{taskmanager_replicacount|default(1)}}

job_classname: {{ job_classname }}
{{ taskmanager_liveness | to_nice_yaml }}


base_config: |
  kafka {
      broker-servers = "{{ kafka_brokers }}"
      zookeeper = "{{ zookeepers }}"
      producer {
        max-request-size = {{ producer_max_request_size }}
      }
    }
    job {
      env = "{{ env_name }}"
      enable.distributed.checkpointing = true
      statebackend {
        blob {
          storage {
            account = "{{ azure_account }}.blob.core.windows.net"
            container = "{{ flink_container_name }}"
            checkpointing.dir = "checkpoint"
          }
        }
        base.url = "wasbs://"${job.statebackend.blob.storage.container}"@"${job.statebackend.blob.storage.account}"/"${job.statebackend.blob.storage.checkpointing.dir}
      }
    }
    task {
      parallelism = 1
      consumer.parallelism = 1
      checkpointing.compressed = {{ checkpoint_compression_enabled|lower }}
      checkpointing.interval = {{ checkpoint_interval }}
      checkpointing.pause.between.seconds = {{ checkpoint_pause_between_seconds }}
      restart-strategy.attempts = {{ restart_attempts }}
      restart-strategy.delay = {{ restart_delay }} # in milli-seconds
    }
    redis {
      host = {{ kp_redis_host }}
      port = 6379
    }
    lms-cassandra {
      host = "{{ core_cassandra_connection_ip }}"
      port = "9042"
    }
    neo4j {
      routePath = "{{ neo4j_route_path }}"
      graph = "domain"
    }

activity-aggregate-updater:
  activity-aggregate-updater: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.coursebatch.job.request
      output.audit.topic = {{ env_name }}.telemetry.raw
      output.failed.topic = {{ env_name }}.activity.agg.failed
      groupId = {{ env_name }}-activity-aggregate-group
    }
    task {
      checkpointing.interval = {{ activity_agg_checkpointing_interval }}
      checkpointing.pause.between.seconds = {{ activity_agg_checkpointing_pause_interval }}
      restart-strategy.attempts = {{ restart_attempts }} # max 3 restart attempts
      restart-strategy.delay = 240000 # in milli-seconds # on max restarts (3) within 4 min the job will fail.
      consumer.parallelism = {{ activity_agg_consumer_parallelism }}
      activity.agg.parallelism = {{ activity_agg_parallelism }}
    }
    lms-cassandra {
        keyspace = "{{ middleware_course_keyspace }}"
        consumption.table = "{{ middleware_consumption_table }}"
        user_activity_agg.table = "{{ middleware_user_activity_agg_table }}"
    }
    redis {
        database {
          relationCache.id = 10
        }
    }
    threshold.batch.read.interval = 60
    threshold.batch.read.size = 1000
    threshold.batch.write.size = 10

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['activity-aggregate-updater'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['activity-aggregate-updater'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['activity-aggregate-updater'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

relation-cache-updater:
  relation-cache-updater: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.content.postpublish.request
      groupId = {{ env_name }}-relation-cache-updater-group
    }
    task {
      consumer.parallelism = {{ relation_cache_updater_consumer_parallelism }}
      parallelism = {{ relation_cache_updater_parallelism }}
    }
    lms-cassandra {
          keyspace = "{{ middleware_hierarchy_keyspace }}"
          table = "{{ middleware_content_hierarchy_table }}"
    }
    redis {
      database.index = 10
    }
    dp-redis {
      host = {{ dp_redis_host }}
      port = 6379
      database.index = 5
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['relation-cache-updater'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['relation-cache-updater'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['relation-cache-updater'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

post-publish-processor:
  post-publish-processor: |+
    include file("/data/flink/conf/base-config.conf")
    kafka {
      input.topic = {{ env_name }}.content.postpublish.request
      groupId = {{ env_name }}-post-publish-processor-group
      publish.topic = {{ env_name }}.learning.job.request
    }
    task {
      consumer.parallelism = {{ post_publish_processor_consumer_parallesim }}
      parallelism = {{ post_publish_processor_parallelism }}
      router.parallelism = {{ post_publish_event_router_parallelism }}
    }
    lms-cassandra {
      keyspace = "{{ middleware_course_keyspace }}"
      batchTable = "course_batch"
    }
    content {
      search {
        basePath = "{{ kp_search_service_base_url }}"
      }
    }
    lms {
      basePath = "{{ lms_service_base_url }}"
    }

  flink-conf: |+
    jobmanager.memory.flink.size: {{ flink_job_names['post-publish-processor'].jobmanager_memory }}
    taskmanager.memory.flink.size: {{ flink_job_names['post-publish-processor'].taskmanager_memory }}
    taskmanager.numberOfTaskSlots: {{ flink_job_names['post-publish-processor'].taskslots }}
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1

certificate-pre-processor:
 certificate-pre-processor: |+
   include file("/data/flink/conf/base-config.conf")
   kafka {
     input.topic = {{ env_name }}.issue.certificate.request
     groupId = {{ env_name }}-certificate-pre-processor-group
     output.topic = {{ env_name }}.generate.certificate.request
     output.failed.topic = {{ env_name }}.certificate.events.failed
   }
   task {
     consumer.parallelism = {{ certificate_pre_processor_consumer_parallelism }}
     parallelism = {{ certificate_pre_processor_parallelism }}
   }
   lms-cassandra {
     keyspace = "{{ middleware_course_keyspace }}"
     batchTable = "course_batch"
     userTable = "user_enrolments"
     assessmentAggregatorTable = "assessment_aggregator"
   }
   content {
     search {
       basePath = "{{ kp_search_service_base_url }}"
     }
     basePath = "{{ kp_content_service_base_url }}"
   }
   lms {
     basePath = "{{ lms_service_base_url }}"
   }
   cert {
     basePath = "{{ cert_service_base_url }}"
   }
   learner-service {
     basePath = "{{ learner_service_base_url }}"
   }

 flink-conf: |+
   jobmanager.memory.flink.size: {{ flink_job_names['certificate-pre-processor'].jobmanager_memory }}
   taskmanager.memory.flink.size: {{ flink_job_names['certificate-pre-processor'].taskmanager_memory }}
   taskmanager.numberOfTaskSlots: {{ flink_job_names['certificate-pre-processor'].taskslots }}
   parallelism.default: 1
   jobmanager.execution.failover-strategy: region
   taskmanager.memory.network.fraction: 0.1
